{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598dd2a-4445-4363-9a2b-5c8fc2d62491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Titanic dataset\n",
    "file_path = 'titanic.csv'  # Adjust this if needed\n",
    "titanic_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e627e4ce-1e6a-43c7-9eb3-e279d95f645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocessing\n",
    "# Drop irrelevant features\n",
    "titanic_data_cleaned = titanic_data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "# Handle missing values\n",
    "titanic_data_cleaned['Age'].fillna(titanic_data_cleaned['Age'].mean(), inplace=True)  # Fill Age with mean\n",
    "titanic_data_cleaned['Embarked'].fillna('missing', inplace=True)  # Fill Embarked with placeholder\n",
    "\n",
    "# Encode categorical variables\n",
    "titanic_data_encoded = pd.get_dummies(titanic_data_cleaned, drop_first=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = titanic_data_encoded.drop(columns=['Survived'])\n",
    "y = titanic_data_encoded['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77b00663-cd15-4708-a989-5f0c2353a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Standardize the data\n",
    "X_mean = X.mean()\n",
    "X_std = X.std()\n",
    "X_standardized = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f4bc16-3c46-4624-b802-bbc86396dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ccf1f96-c6e3-4fb5-bdda-0cce18b01ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.46%\n",
      "Precision: 74.46%\n",
      "Recall: 70.76%\n",
      "F1 Score: 72.56%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Loss function (Binary Cross-Entropy)\n",
    "def binary_cross_entropy(y, y_pred):\n",
    "    return -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "\n",
    "# Gradient Descent for Logistic Regression\n",
    "def train_logistic_regression(X, y, learning_rate=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros(n)\n",
    "    bias = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Linear model\n",
    "        z = np.dot(X, weights) + bias\n",
    "        y_pred = sigmoid(z)\n",
    "\n",
    "        # Compute gradients\n",
    "        dw = np.dot(X.T, (y_pred - y)) / m\n",
    "        db = np.sum(y_pred - y) / m\n",
    "\n",
    "        # Update weights and bias\n",
    "        weights -= learning_rate * dw\n",
    "        bias -= learning_rate * db\n",
    "\n",
    "        # Optionally print loss\n",
    "        # if epoch % 100 == 0:\n",
    "        #     loss = binary_cross_entropy(y, y_pred)\n",
    "        #     print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# Prediction\n",
    "def predict(X, weights, bias, threshold=0.5):\n",
    "    z = np.dot(X, weights) + bias\n",
    "    y_pred = sigmoid(z)\n",
    "    return (y_pred >= threshold).astype(int)\n",
    "\n",
    "# Metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "# Example Usage (Assuming `X` and `y` are preprocessed)\n",
    "weights, bias = train_logistic_regression(X, y, learning_rate=0.01, epochs=1000)\n",
    "y_pred = predict(X, weights, bias)\n",
    "\n",
    "accuracy, precision, recall, f1_score = calculate_metrics(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28788546-17ed-4b70-b25a-4909ef4ae476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad4b74-769e-49b8-b398-ac93267fd147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
